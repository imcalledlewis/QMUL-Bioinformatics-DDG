{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, sys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct GWAS column dataset by moving chromosome coordinates to chr_id & chr_pos cols and replacing with rsIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for variants with no chromosomal coordinates and created a separated list of variants and dataframe\n",
    "df = pd.read_table('TSVs/gwas_trimmed.tsv') \n",
    "df2 = df\n",
    "df2 = df2.drop(df2[df2['rsid'].str.contains('rs')].index)\n",
    "df2 = df2.reset_index()\n",
    "df2 = df2.drop('index', axis=1)\n",
    "variant_list = df2[\"rsid\"].tolist() \n",
    "\n",
    "# create lists for API\n",
    "chrom_list = []\n",
    "chrom_pos_list = []\n",
    "for variant in variant_list:\n",
    "    variant_split = variant.split(\":\")\n",
    "    chrom_list.append(variant_split[0].replace(\"chr\", \"\"))\n",
    "    chrom_pos_list.append(variant_split[1])\n",
    "    \n",
    "# assign coordinate values to correct columns of each SNP\n",
    "for ind in df2.index:\n",
    "    df2.loc[ind,'chr_pos'] = chrom_pos_list[ind]\n",
    "    df2.loc[ind,'chr_id'] = chrom_list[ind]\n",
    "    \n",
    "# API for requesting variant information based on SNP chromosomal coordinates\n",
    "def variant_search_API(chrom,chrom_pos):\n",
    "    \n",
    "    server = \"https://rest.ensembl.org\"\n",
    "    ext = f\"/overlap/region/human/{chrom}:{chrom_pos}-{chrom_pos}?feature=variation\"\n",
    "\n",
    "    r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n",
    "\n",
    "    if not r.ok:\n",
    "      r.raise_for_status()\n",
    "      sys.exit()\n",
    "\n",
    "    decoded = r.json()\n",
    "    return decoded\n",
    "\n",
    "# empty dataframe\n",
    "variant_df = pd.DataFrame(columns=['rsid','chr_pos','chr_id']) \n",
    "# list for variants that cannot be found\n",
    "invalid_variant = []\n",
    "# loop to build dataframe\n",
    "n = 0\n",
    "for chrom,chrom_pos in zip(chrom_list,chrom_pos_list):\n",
    "    n += 1\n",
    "    try:\n",
    "        decoded = variant_search_API(chrom,chrom_pos)\n",
    "        rsID = decoded[0]['id']\n",
    "        print(f\"{n}-{rsID}\") # print successfully retrieved SNPs\n",
    "    except:\n",
    "        invalid_variant.append(chrom + \":\" + chrom_pos)\n",
    "        print(f\"{n}-{chrom}:{chrom_pos}\") # print chromsomal coordinates which could not successfully retrieve SNPs\n",
    "        continue\n",
    "    variant_list = [rsID, chrom_pos, chrom]\n",
    "    variant_row = pd.DataFrame(variant_list).T\n",
    "    variant_row.columns = variant_df.columns\n",
    "    variant_df = pd.concat([variant_df, variant_row])\n",
    "\n",
    "invalid_variant = list(dict.fromkeys(invalid_variant)) # remove duplicates from list\n",
    "print(f\"Couldn't get rsids for variants: {invalid_variant}\")   \n",
    "# merge modified dataset with dataframe containing new SNP rsIDs\n",
    "df2 = df2.drop('rsid', axis=1) # drop rsid column from modified dataset\n",
    "df_filled = pd.merge(variant_df, df2, on=['chr_pos','chr_id']).drop_duplicates() # merge based on 'chr_pos' and 'chr_id' columns\n",
    "\n",
    "# create another separate dataset with row that have rsID SNPs\n",
    "df3 = df\n",
    "df3 = df3.loc[df3['chr_pos'].notnull()]\n",
    "\n",
    "# concat df originally containg SNP rsIDs with new df corrected with additional SNP rsIDs\n",
    "df_corrected = pd.concat([df3, df_filled])\n",
    "df_corrected = df_corrected[df_corrected[\"rsid\"].str.contains(\"rs\") == True] # remove any entries in the rsID column without rsIDs\n",
    "# write out TSV file\n",
    "df_corrected.chr_id = df_corrected.chr_id.astype(int) \n",
    "df_corrected.chr_pos = df_corrected.chr_pos.astype(int) \n",
    "df_corrected.to_csv('TSVs/T1D_GWAS_add.tsv', sep ='\\t', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add missing mapped gene entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('TSVs/T1D_GWAS_add.tsv', index_col = \"i\") # GWAS data \n",
    "df2 = df[df['mapped_gene'].isna()] # Filter for rows without mapped genes\n",
    "SNP_list = df2['rsid'].to_list() # Extract list of SNPs\n",
    "\n",
    "def add_mapped_gene(rsID):\n",
    "\n",
    "    server = \"https://rest.ensembl.org\"\n",
    "    ext = f\"/variation/human/{rsID}?phenotypes=1\"\n",
    "\n",
    "    r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n",
    "\n",
    "    if not r.ok:\n",
    "      r.raise_for_status()\n",
    "      sys.exit()\n",
    "\n",
    "    decoded = r.json()\n",
    "    return decoded\n",
    "\n",
    "# Find missing mapped genes and add to dataframe \n",
    "for SNP in SNP_list:\n",
    "    decoded = add_mapped_gene(SNP) # request SNP data from Ensembl \n",
    "    # try to extract a mapped gene from dictionary\n",
    "    try:\n",
    "        mapped_gene = decoded['phenotypes'][0]['genes']\n",
    "        SNP_ind = df2[df2['rsid']==SNP].index.values  # find SNP index in dataframe\n",
    "        df.loc[SNP_ind,'mapped_gene'] = mapped_gene # replace empty cell in original dataframe with new mapped gene from SNP data\n",
    "    except IndexError:\n",
    "        continue\n",
    "# write out corrected GWAS dataset as TSV\n",
    "df.to_csv('TSVs/T1D_GWAS_add.tsv', sep ='\\t')\n",
    "print(\"Done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cumulative chromosome positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('TSVs/T1D_GWAS_add.tsv') \n",
    "\n",
    "# -log the P-values and column to the table\n",
    "df['-logp']= - np.log(df['p_value'])\n",
    "\n",
    "# Put variants in order by max position in chromosome\n",
    "running_pos = 0 # moves all integers down so first pos is 0\n",
    " \n",
    "cumulative_pos = [] # create list of new series for position in whole genome\n",
    "\n",
    "for chrom, group_df in df.groupby('chr_id'): # Group the region in each chromosome together\n",
    "    cumulative_pos.append(group_df['chr_pos'] + running_pos) \n",
    "    running_pos+= group_df['chr_pos'].max() #tells us the last position in each chromosome\n",
    "\n",
    "# Position of variant relative to whole chromosome, add column to the table    \n",
    "df['cumulative_pos'] = pd.concat(cumulative_pos) \n",
    "# write out TSV file\n",
    "df.to_csv('TSVs/T1D_GWAS_add.tsv', sep ='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
